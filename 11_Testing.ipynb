{
 "metadata": {
  "celltoolbar": "Slideshow",
  "name": "",
  "signature": "sha256:41936b08260b425f2c44bc3cdca2ed4ad765067f89589c1f094f5d64cbf7b306"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Testing\n",
      "======="
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "As a scientist, you should want to prove that everything you do is as correct as possible.\n",
      "\n",
      ">  http://www.sqlite.org/testing.html\n",
      ">\n",
      ">  The reliability and robustness of SQLite is achieved in part by thorough and careful testing.\n",
      ">\n",
      ">  As of version 3.7.14, the SQLite library consists of approximately 81.3 KSLOC of C code. (KSLOC means thousands of \"Source Lines Of Code\" or, in other words, lines of code excluding blank lines and comments.) By comparison, the project has 1124 times as much test code and test scripts - 91421.1 KSLOC. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Regression testing\n",
      "------------------\n",
      "\n",
      "Typically, you might bundle a code with a few examples and the output that has been verified as 'correct'. Once you have made changes to the code, you might run the  examples again to check that you still get the correct results. If you cause a failure in something that works fine when you make a change, that is called a **regression** bug. These examples test your code as a whole.\n",
      "\n",
      "*Congratulations* on actually testing; that's more than a lot of people do!\n",
      "\n",
      "There are other, more systematic and thorough ('better') ways to test code! By testing individual bits of the code completely independently you can isolate failures, prevent cancelled errors, test every nook and cranny, automate testing, cover all possible outcomes and many other things."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Errors\n",
      "------\n",
      "\n",
      "We need a little information on what errors actually are.\n",
      "\n",
      "* **Crashes** are where the program does something that it shouldn't with the computer.\n",
      "    - 'Segmentation fault', 'bus error', 'BSOD' and some others all indicate that something bad has happened.\n",
      "    - Your program will stop immediately (and maybe crash your whole system).\n",
      "    - Crashes are ofthen a sign of _unsafe_ programming.\n",
      "    - Python should never crash; if it does then you found a bug!\n",
      "\n",
      "* Python aims to be safe and *fail gracefully*, which it does with the inclusion of **exception** classes. \n",
      "    - When the code hits something that is not right it **raises** an appropriate error \n",
      "    - The error gets passed up the calling functions until the code exits showing what the exception was.\n",
      "\n",
      "            ZeroDivisionError: integer division or modulo by zero\n",
      "            NameError: name 'spam' is not defined\n",
      "            TypeError: cannot concatenate 'str' and 'int' objects\n",
      "\n",
      "    - Different errors that can occur show you that they are specific to the situation that raised them.\n",
      "\n",
      "* One of the benefits of exceptions is that you can **catch** or **trap** \n",
      "    - Uncaught exceptions will exit the program\n",
      "    - Caught errors allow us to take measures to deal with whatever caused the error and continue.\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Try/except\n",
      "----------"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def happy_divide(x, y):\n",
      "    \"\"\"A divisor that always makes you smile.\"\"\"\n",
      "    try:\n",
      "        result = x / y\n",
      "    except ZeroDivisionError:\n",
      "        print(\"Division by zero!\")\n",
      "        return(float('inf'))\n",
      "    else:\n",
      "        print(\"Result is {0:.3f}\".format(result))\n",
      "    finally:\n",
      "        print(\"Keep smiling :D\")\n",
      "\n",
      "happy_divide(12.2, 3.5)\n",
      "happy_divide(9.7, 0.0)"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "-"
      }
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Result is 3.486\n",
        "Keep smiling :D\n",
        "Division by zero!\n",
        "Keep smiling :D\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 1,
       "text": [
        "inf"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "+ The code that could raise the error goes in the `try` block. \n",
      "+ The `except` block defines what should happen if a specified error is encountered. \n",
      "+ Since the try block exits immediately on error, the `finally` block defines any cleanup that will always be executed whether the try block is successful or not (i.e. closing network connections, files, etc).\n",
      "\n",
      "\n",
      "We could achieve the same thing by checking if `y == 0` first, but using exceptions is more Pythonic:\n",
      "\n",
      "+ EAFP - It's easier to ask for forgiveness than permission,\n",
      "    + vs. LBYL - Look before you leap;\n",
      "+ Allows us to handle several errors succinctly;\n",
      "+ Ensures that cleanup is always carried out;\n",
      "+ The computational cost of setting up a `try` block is fairly minimal in comparison."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Silent errors\n",
      "-------------"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "try:\n",
      "    # anything could go in here\n",
      "    \"number\" + 22 / 0\n",
      "    function_wtih_typoo()\n",
      "except:\n",
      "    # DON'T DO THIS UNLESS YOU KNOW WHAT YOU ARE DOING\n",
      "    pass"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "-"
      }
     },
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A **bare except** (no Exception class specified) will catch any errors. *Don't do this*! You must be explicit about the errors you want to catch or you will get no information on what is raising the error! This can also do bad things like catch \"Ctrl-C\" as KeyboardInterrupt and prevent it from killing your program.\n",
      "\n",
      "The `pass` allows the error to pass silently *Don't do this* unless it is what you intend! \"Errors should never pass silently. Unless explicitly silenced.\""
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Custom Exceptions\n",
      "-----------------"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Make your own custom Exceptions very descriptive\n",
      "class NotBritishError(Exception):\n",
      "    pass\n",
      "\n",
      "class VeryBritishError(Exception):\n",
      "    def __init__(self, message):\n",
      "        print(\"I'm inside a customised exception!\")\n",
      "        message = \"Oh, jolly good! {0}\".format(message)\n",
      "        Exception.__init__(self, message)  # use the superclass"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Exceptions are just classes. \n",
      "\n",
      "+ Use them to identify specific errors with names that are relevant for your code.\n",
      "+ They are Defined by subclassing the base `Exception`. \n",
      "+ They can actually have any code that you like in them (try overriding the `__init__` method);\n",
      "    + It is probably best to keep them simple rather than adding hidden happenings.\n",
      "+ To signal or propagate an error simply use the `raise` statement at the appropriate point!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "try:\n",
      "    raise NotBritishError(\"Fiddlesticks!\")\n",
      "except NotBritishError as err:\n",
      "    print(err)\n",
      "    # you could raise err here again if you\n",
      "    # need to propogate the error further\n",
      "\n",
      "try:\n",
      "    raise VeryBritishError(\"Throwing a wobbly!\")\n",
      "except (NotBritishError, VeryBritishError) as err:\n",
      "    # Either error will get us here\n",
      "    print(err)\n",
      "    print(type(err))"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Fiddlesticks!\n",
        "I'm inside a customised exception!\n",
        "Oh, jolly good! Throwing a wobbly!\n",
        "<class '__main__.VeryBritishError'>\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Assertions\n",
      "----------\n",
      "\n",
      "The `assert` statement is a simple test that can be integrated with code to ensure that things you know must be true are always true. This can help dealing with assumptions that you make in your code and tracking down bugs that you might not expect."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def kelvin_to_celsius(temperature):\n",
      "    \"\"\"Convert an absolute Kelvin temperature to friendly \u00b0C\"\"\"\n",
      "    assert temperature >= 0, \"Colder than absolute zero!\"\n",
      "    return temperature - 273.15\n",
      "\n",
      "print(kelvin_to_celsius(298))\n",
      "assert kelvin_to_celsius(273.15) == 0.0\n",
      "\n",
      "#print(kelvin_to_celsius(-12))\n",
      "#AssertionError: Colder than absolute zero!"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "24.85\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Assertions can be useful quick checks for some invariants. However, it can be messy interleaving them with your code, they stop your code executing completely on error, and they can have an impact on performace if they are not optimised out."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Unit testing\n",
      "------------\n",
      "\n",
      "Unit testing is the practice of taking small parts of code (**units**) and creating extensive test suites to ensure that they work as expected for all possible cases.\n",
      "\n",
      "This may sound like a lot of work, and it is, but it provides an automated system to check that any changes you make to the code do not break the implementation and in the case of **test driven development** the tests are written first as targets for the implementation. The key to unit testing is thinking about all the **edge cases** that would trip up your code."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%file kelvin.py\n",
      "\"\"\"\n",
      "kelvin.py\n",
      "\n",
      "Implementation of conversions between Kelvin and Celsius.\n",
      "\n",
      "Provides two functions kelvin_to_celsius and celsius_to_kelvin.\n",
      "\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "def kelvin_to_celsius(temperature):\n",
      "    \"\"\"Return a Kelvin scale temperature as Celsius.\"\"\"\n",
      "    if temperature < 0.0:\n",
      "        raise ValueError(\"Colder than absolute zero!\")\n",
      "    return temperature - 273.15\n",
      "\n",
      "\n",
      "def celsius_to_kelvin(temperature):\n",
      "    \"\"\"Return a Celsius scale temperature as Kelvin .\"\"\"\n",
      "    if temperature < -273:\n",
      "        raise ValueError(\"Colder than absolute zero!\")\n",
      "    return temperature + 273"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Overwriting kelvin.py\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%file kelvin-test.py\n",
      "##\n",
      "# Unit testing code; usually separate\n",
      "##\n",
      "\n",
      "import unittest\n",
      "\n",
      "from kelvin import kelvin_to_celsius, celsius_to_kelvin\n",
      "\n",
      "\n",
      "# unittest.TestCase is detects where it has been subclassed to pick\n",
      "# up the unit tests.\n",
      "class KelvinCelsiusKnownTests(unittest.TestCase):\n",
      "    \"\"\"Test cases for working kelvin to celsius.\"\"\"\n",
      "    # tests have a 'test' prefix to their name.\n",
      "    def test_positive(self):\n",
      "        \"\"\"Known result with known input.\"\"\"\n",
      "        self.assertEqual(kelvin_to_celsius(298.15), 25.0)\n",
      "\n",
      "    def test_zero(self):\n",
      "        \"\"\"Edge case, deal with zero but not below.\"\"\"\n",
      "        self.assertEqual(kelvin_to_celsius(0.0), -273.15)\n",
      "\n",
      "\n",
      "class CelsiusKelvinKnownTests(unittest.TestCase):\n",
      "    \"\"\"Test cases for working celsius to kelvin.\"\"\"\n",
      "    def test_zero(self):\n",
      "        \"\"\"Known result for known input.\"\"\"\n",
      "        self.assertEqual(celsius_to_kelvin(0.0), 273.15)\n",
      "\n",
      "    def test_positive(self):\n",
      "        \"\"\"Known result for known positive input.\"\"\"\n",
      "        self.assertEqual(celsius_to_kelvin(10.0), 283.15)\n",
      "\n",
      "    def test_absolute_zero(self):\n",
      "        \"\"\"Edge case, deal with absolute zero but not below.\"\"\"\n",
      "        self.assertEqual(celsius_to_kelvin(-273.15), 0.0)\n",
      "\n",
      "\n",
      "class KelvinCelsiusErrorTests(unittest.TestCase):\n",
      "    \"\"\"Known errors for Celsius Kelvin conversion.\"\"\"\n",
      "    def test_range_kelvin(self):\n",
      "        \"\"\"Should not convert below absolute zero.\"\"\"\n",
      "        self.assertRaises(ValueError, kelvin_to_celsius, -1.0)\n",
      "\n",
      "    def test_range_celsius(self):\n",
      "        \"\"\"Should not convert below absolute zero.\"\"\"\n",
      "        self.assertRaises(ValueError, celsius_to_kelvin, -273.16)\n",
      "\n",
      "\n",
      "# modularisation of code hint here:\n",
      "def main():\n",
      "    \"\"\"Run unit tests.\"\"\"\n",
      "    unittest.main()\n",
      "    #unittest.main(verbosity=2)  # use for extended output\n",
      "    pass\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    main()"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Overwriting kelvin-test.py\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Tests are:\n",
      "\n",
      "+ separate from the main code - `kelvin-tests.py`;\n",
      "+ designed to be indiviual units\n",
      "+ each test a single piece of functionality of a single piece of code\n",
      "+ test typical cases\n",
      "+ make sure things work at the defined limits and not beyond\n",
      "+ validate inputs and outputs\n",
      "+ are reproducible\n",
      "\n",
      "You could envisage every function having a number of test cases for all ranges of inputs and outputs."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "The `unittest` module does all the hard work for us. First we logically break down our tests into values that we know that work and some error cases. Each set should subclass `unittest.TestCase`. With each class you have to write **test cases** as methods with names that start with 'test'. Unfortunately the unittest is heavily influenced by Java so you might see mixtures of naming styles, unittests's methods are headlessCamelCase whereas Python should probably be lowercase_with_underscores, in these examples we will use `test_somthing` rather than `testSomething()`.\n",
      "\n",
      "A **test case** is where you define the test condition, in unittest we do this with assert methods, the major ones that cover most use cases are:\n",
      "\n",
      "* `assertEqual(first, second)` tests that both arguments satisfy `first == second`\n",
      "* `assertTrue(x)` tests that `x` evaluates to be `True`\n",
      "* `assertRaises(exc, fun, *args, **kwds)` tests that when `fun` runs with the given arguments it raises the `exc` error\n",
      "\n",
      "The **test suite** is a collection of test cases (grouped in to individual classes here), or a collection of test suites (here the code represents a test suite).\n",
      "\n",
      "The **test runner** is invoked to run all the tests, in this case the `unittest.main()` command collects the tests that have been defined and runs them all. (There are other ways to invoke individual tests, but the benefit of unit testing is that the entire suite should always pass)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!python kelvin-test.py"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "EFF....\n",
        "======================================================================\n",
        "ERROR: test_absolute_zero (__main__.CelsiusKelvinKnownTests)\n",
        "Edge case, deal with absolute zero but not below.\n",
        "----------------------------------------------------------------------\n",
        "Traceback (most recent call last):\n",
        "  File \"kelvin-test.py\", line 36, in test_absolute_zero\n",
        "    self.assertEqual(celsius_to_kelvin(-273.15), 0.0)\n",
        "  File \"C:\\Users\\Tom\\Documents\\Work\\IPythonNotebook\\CHM8309I_2014\\kelvin.py\", line 21, in celsius_to_kelvin\n",
        "    raise ValueError(\"Colder than absolute zero!\")\n",
        "ValueError: Colder than absolute zero!\n",
        "\n",
        "======================================================================\n",
        "FAIL: test_positive (__main__.CelsiusKelvinKnownTests)\n",
        "Known result for known positive input.\n",
        "----------------------------------------------------------------------\n",
        "Traceback (most recent call last):\n",
        "  File \"kelvin-test.py\", line 32, in test_positive\n",
        "    self.assertEqual(celsius_to_kelvin(10.0), 283.15)\n",
        "AssertionError: 283.0 != 283.15\n",
        "\n",
        "======================================================================\n",
        "FAIL: test_zero (__main__.CelsiusKelvinKnownTests)\n",
        "Known result for known input.\n",
        "----------------------------------------------------------------------\n",
        "Traceback (most recent call last):\n",
        "  File \"kelvin-test.py\", line 28, in test_zero\n",
        "    self.assertEqual(celsius_to_kelvin(0.0), 273.15)\n",
        "AssertionError: 273.0 != 273.15\n",
        "\n",
        "----------------------------------------------------------------------\n",
        "Ran 7 tests in 0.004s\n",
        "\n",
        "FAILED (failures=2, errors=1)\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Tests run in **alphabetical order**! On a good day, we will just see `OK`, but this example is designed to fail. At the very top of our output we see `EFF....` which is the result of our testing:\n",
      "\n",
      "* `.` is printed for each test that passes successfully\n",
      "* `F` is printed for each test that fails\n",
      "* `E` is printed where an unexpected error is encountered\n",
      "\n",
      "All the tests run, even if some fail, so you can see the complete roundup at the end. All of the errors and failures are output so we can see where our code fails to satisfy the test cases."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Testing classes\n",
      "---------------\n",
      "\n",
      "For testing more than just functions we need to `setUp` our environment first. The setup often includes instancing classes and setting the required state before testing."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%file functional_group.py\n",
      "\n",
      "from datetime import datetime\n",
      "from operator import add\n",
      "\n",
      "class MovableThing(object):\n",
      "    \"\"\"Base class for things that have a position and motion.\"\"\"\n",
      "    def __init__(self, position=[0, 0, 0]):\n",
      "        \"\"\"Place subclass at the position or origin.\"\"\"\n",
      "        self._position = position\n",
      "        self.__timestamp = datetime.now()\n",
      "\n",
      "    def move(self, vector):\n",
      "        \"\"\"Displace the Thing by the given amount.\"\"\"\n",
      "        self._position = [add(here, move) \n",
      "                          for(here, move) in \n",
      "                          zip(self._position, vector)]\n",
      "    \n",
      "    def locate(self):\n",
      "        \"\"\"Tell where the Thing is located.\"\"\"\n",
      "        return self._position\n",
      "    \n",
      "    def what_am_i(self):\n",
      "        \"\"\"Information that needs to be subclassed.\"\"\"\n",
      "        raise NotImplementedError\n",
      "\n",
      "class FunctionalGroup(MovableThing):\n",
      "    \"\"\"A single functional group.\"\"\"\n",
      "    owner = 'tdaff'\n",
      "    \n",
      "    def __init__(self, name, formula, position=[0, 0, 0]):\n",
      "        \"\"\"Create a new FunctionalGroup at the position or origin.\"\"\"\n",
      "        self.name = name\n",
      "        self.formula = formula\n",
      "        MovableThing.__init__(self, position)\n",
      "    \n",
      "    def __str__(self):\n",
      "        \"\"\"Fancy string representation for use with print.\"\"\"\n",
      "        return self.what_am_i()\n",
      "    \n",
      "    def __iadd__(self, other):\n",
      "        \"\"\"Overload += to append other groups.\"\"\"\n",
      "        self.name = self.name + other.name\n",
      "        self.formula = self.formula + other.formula\n",
      "        return self\n",
      "\n",
      "    def what_am_i(self):\n",
      "        \"\"\"Give some formatted information on this object.\"\"\"\n",
      "        return \"I'm a {} group at {}\".format(self.name, self.locate())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Overwriting functional_group.py\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%file functional_group-test.py\n",
      "#!usr/bin/env python\n",
      "\n",
      "\"\"\"\n",
      "Unit testing for FunctionalGroup demonstrating setUp.\n",
      "\n",
      "\"\"\"\n",
      "\n",
      "import unittest\n",
      "\n",
      "# Sometimes you may also need to test the import\n",
      "from functional_group import FunctionalGroup\n",
      "\n",
      "\n",
      "class TestMovement(unittest.TestCase):\n",
      "    \"\"\"Test movement aspects of a functional group.\"\"\"\n",
      "    def setUp(self):\n",
      "        \"\"\"Instance a new FunctionalGroup as an attribute.\"\"\"\n",
      "        self.functional_group = FunctionalGroup('amine', 'NH2')\n",
      "\n",
      "    def test_movement(self):\n",
      "        \"\"\"Test initial position and position after moving.\"\"\"\n",
      "        self.assertEqual(self.functional_group.locate(), [0, 0, 0])\n",
      "        self.functional_group.move([1.1, 2.2, 3.3])\n",
      "        self.assertEqual(self.functional_group.locate(), [1.1, 2.2, 3.3])\n",
      "\n",
      "    def test_invalid_vector(self):\n",
      "        \"\"\"Make sure that movement only takes a vector.\"\"\"\n",
      "        self.assertRaises(TypeError, self.functional_group.move, 'notavector')\n",
      "\n",
      "\n",
      "class TwoGroupCase(unittest.TestCase):\n",
      "    \"\"\"Generic class to be used for tests with two groups.\"\"\"\n",
      "    def setUp(self):\n",
      "        self.group_one = FunctionalGroup('Nitro', 'NO2')\n",
      "        self.group_two = FunctionalGroup('Amine', 'NH2')\n",
      "\n",
      "\n",
      "class TestAddGroups(TwoGroupCase):\n",
      "    \"\"\"Functional groups should add in a consistent manner.\"\"\"\n",
      "    def test_add_groups(self):\n",
      "\n",
      "        self.group_one += self.group_two\n",
      "        self.assertEqual(self.group_one.name, 'NitroAmine')\n",
      "\n",
      "class TestWhatAmI(TwoGroupCase):\n",
      "    \"\"\"Test string representation.\"\"\"\n",
      "    def test_string_repr(self):\n",
      "        \"\"\"what_am_i gets passed to a print(), but we can't test directly.\"\"\"\n",
      "        self.assertEqual(self.group_two.what_am_i(),\n",
      "                         \"I'm a Amine group at [0, 0, 0]\")\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    unittest.main(verbosity=2)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Overwriting functional_group-test.py\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Coverage.py\n",
      "-----------\n",
      "\n",
      "**Coverage** is a measure of how much of your code is executed is used by your test suite. There is a simple tool that can be used with Python that will keep track of every statement that is executed and show you where your tests do not reach.\n",
      "\n",
      "You can run coverage on your code easily and get interactive results. For the above example see [http://titan.chem.uottawa.ca/CHM8309I/htmlcov](http://titan.chem.uottawa.ca/CHM8309I/htmlcov)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!coverage run functional_group-test.py\n",
      "!coverage html"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "test_add_groups (__main__.TestAddGroups) ... ok\n",
        "test_invalid_vector (__main__.TestMovement)\n",
        "Make sure that movement only takes a vector. ... ok\n",
        "test_movement (__main__.TestMovement)\n",
        "Test initial position and position after moving. ... ok\n",
        "test_string_repr (__main__.TestWhatAmI)\n",
        "what_am_i gets passed to a print(), but we can't test directly. ... ok\n",
        "\n",
        "----------------------------------------------------------------------\n",
        "Ran 4 tests in 0.003s\n",
        "\n",
        "OK\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Coverage just keeps track of statements and is not a perfect measure. Testing is a complex problem and *thinking about the edge cases that define the boundaries of your problem* is a very important part of writing code. *It is up to you to design good tests that give you the appropriate coverage of possbile conditions and code paths.*"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Monkey testing\n",
      "--------------\n",
      "\n",
      "+ In the unit testing so far, we have specifically defined inputs, outputs and edge cases.\n",
      "+ Monkey testing and other forms of *fuzzing* generate streams of _randomised data_ that aim to expose unexpected cases and how things deal with 'bad' data.\n",
      "+ For cases where you can expect all kinds of user input this can be useful (think forms on webpages).\n",
      "+ For strictly defined componenets of scientific systems, it is better to maintain the _reproducibility_ of the tests and the ability to work with specified limits.\n",
      "+ When generating data it is easy to end up just testing the same case every time.\n",
      "+ Remember to keep track of the _random seeds_ so you can run the same test again.\n",
      "\n",
      "![monkeys](files/Images/thousand_monkeys.png)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Test driven development\n",
      "-----------------------\n",
      "\n",
      "A concept of **extreme programming**!\n",
      "\n",
      "+ Write the tests first for very small sections of code\n",
      "+ Write the code to fit the test cases\n",
      "+ Write more tests\n",
      "+ Iterate until the code is complete"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}